{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data\n",
    "\n",
    "Load lyrics with artist info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "chunking lyrics\n",
      "{'inp_ids': tensor([    1,   362,    31,     8,  1458,     3,     6,    49,    46,\n",
      "            7,   157,   152,     3,    25,    36,    11,   715,   244,\n",
      "            5,   703,    22,   639,     3,     7,    50,  5785,    24,\n",
      "         1991,    17,     8,  7104,     3,     8,     4,    35,    11,\n",
      "          389]), 'inp_words': ['<START>', 'ready', 'for', 'the', 'danger', '<EOL>', 'i', \"'ll\", 'get', 'you', 'home', 'again', '<EOL>', 'we', 'got', 'a', 'green', 'light', ',', 'hang', 'on', 'tight', '<EOL>', 'you', 'can', 'rearrange', 'your', 'bags', 'in', 'the', 'aisle', '<EOL>', 'the', 'airline', 'with', 'a', 'smile'], 'out_words': ['ready', 'for', 'the', 'danger', '<EOL>', 'i', \"'ll\", 'get', 'you', 'home', 'again', '<EOL>', 'we', 'got', 'a', 'green', 'light', ',', 'hang', 'on', 'tight', '<EOL>', 'you', 'can', 'rearrange', 'your', 'bags', 'in', 'the', 'aisle', '<EOL>', 'the', 'airline', 'with', 'a', 'smile', '<END>'], 'artist_id': [], 'out_ids': tensor([  362,    31,     8,  1458,     3,     6,    49,    46,     7,\n",
      "          157,   152,     3,    25,    36,    11,   715,   244,     5,\n",
      "          703,    22,   639,     3,     7,    50,  5785,    24,  1991,\n",
      "           17,     8,  7104,     3,     8,     4,    35,    11,   389,\n",
      "            2]), 'artist': []} 371574\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import string, re\n",
    "import unidecode\n",
    "import random, math, time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorboardX\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils import rnn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "MAX_LEN = 50\n",
    "BATCH_SIZE = 8\n",
    "USE_ARTIST = False\n",
    "\n",
    "# special tokens\n",
    "EOL = '<EOL>'\n",
    "UNK = '<UNK>'\n",
    "START = '<START>'\n",
    "END = '<END>'\n",
    "PAD = '<padding>'\n",
    "PAD_ID = 0\n",
    "\n",
    "    \n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, pkl_file, vocab_file=None, vocab_size=10000, chunk_size=0, use_artist=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with lyrics.\n",
    "            chunk_size (int): Number of lyric lines to use as single sample. If 0, use song's entire lyrics\n",
    "        \"\"\"\n",
    "        self.lyrics = pickle.load(open(pkl_file,'rb'), encoding='latin1')\n",
    "        \n",
    "        self.vocab_len = vocab_size\n",
    "        if vocab_file == None:\n",
    "            vocab_file = re.sub('.pkl','.vocab',pkl_file)\n",
    "            if not os.path.exists(vocab_file):\n",
    "                self.create_vocab(vocab_file)\n",
    "            \n",
    "        self.vocab = [x.split()[0] for x in open(vocab_file).read().splitlines()][:self.vocab_len]\n",
    "        self.vocab = [START, END, EOL, UNK] + self.vocab\n",
    "        self.vocab.insert(PAD_ID, PAD)\n",
    "        \n",
    "        self.use_artist = use_artist\n",
    "        if self.use_artist:\n",
    "            self.artists = sorted(set([x['artist'] for x in self.lyrics]))\n",
    "            self.num_artists = len(self.artists)\n",
    "            \n",
    "        # chunk lyrics\n",
    "        print(\"chunking lyrics\")\n",
    "        self.chunk_size = chunk_size\n",
    "        if self.chunk_size > 0:\n",
    "            chunked_lyrics = []\n",
    "            for song in self.lyrics:\n",
    "                lines = re.split(r'\\n',song['lyrics'])\n",
    "                for i in range(len(lines) - self.chunk_size+1):\n",
    "                    chunk = '\\n'.join(lines[i:i+self.chunk_size])\n",
    "                    song['lyrics'] = chunk\n",
    "                    chunked_lyrics += [song.copy()]\n",
    "            self.lyrics = chunked_lyrics\n",
    "                    \n",
    "    def create_vocab(self,file_name):\n",
    "        num_songs = len(self.lyrics)\n",
    "        print('creating vocabulary for %d songs'%num_songs)\n",
    "        \n",
    "        vocab = []\n",
    "        for i,e in enumerate(self.lyrics):\n",
    "            if i%(num_songs/10)==0:\n",
    "                print('finished %d/%d songs (%.2f%%)'%(i,num_songs,float(i)/num_songs))\n",
    "            vocab += [w.lower() for w in e['lyrics'].split()]\n",
    "        vocab = Counter(vocab)\n",
    "        \n",
    "        # save up to 100,000 words\n",
    "        with open(file_name,'w') as f:\n",
    "            for i,(a,n) in enumerate(vocab.most_common()):\n",
    "                if i==100000:\n",
    "                    break\n",
    "                if n < 5:\n",
    "                    break\n",
    "                f.write('%s\\t%s\\n'%(a,n))\n",
    "\n",
    "    def __len__(self):\n",
    "        # or length of chunked lyrics?\n",
    "        return len(self.lyrics)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        samp = self.lyrics[idx]\n",
    "        sample = {'inp_words':[],'out_words':[],'inp_ids':[],'out_ids':[],'artist':[],'artist_id':[]}\n",
    "        tokenized_lyrics = [START] + re.sub('\\n',' %s '%EOL, samp['lyrics']).split() + [END]\n",
    "        \n",
    "        sample['inp_words'] = tokenized_lyrics[:-1][:MAX_LEN]\n",
    "        sample['out_words'] = tokenized_lyrics[1:MAX_LEN+1]\n",
    "        sample['inp_ids'] = self.word_tensor(sample['inp_words'])\n",
    "        sample['out_ids'] = self.word_tensor(sample['out_words'])\n",
    "        \n",
    "        if self.use_artist:\n",
    "            sample['artist'] = samp['artist']\n",
    "            sample['artist_id'] = self.artists.index(sample['artist'])\n",
    "    \n",
    "        return sample\n",
    "        \n",
    "    # Turn list of words into list of longs\n",
    "    def word_tensor(self,words):\n",
    "        tensor = torch.zeros(len(words)).long()\n",
    "        for w in range(len(words)):\n",
    "            try:\n",
    "                tensor[w] = self.vocab.index(words[w])\n",
    "            except Exception as e:\n",
    "                tensor[w] = self.vocab.index(UNK)\n",
    "        return Variable(tensor)\n",
    "\n",
    "    def word2id(word):\n",
    "        try:\n",
    "            idx = self.vocab.index(word)\n",
    "        except Exception as e:\n",
    "            idx = self.vocab.index(UNK)\n",
    "        return idx\n",
    "    \n",
    "    def id2word(idx):\n",
    "        return self.vocab[idx]\n",
    "\n",
    "Data = LyricsDataset('lyrics/artists_train.pkl', vocab_file='lyrics/lyrics_top_artists.vocab', \n",
    "                     chunk_size=5,use_artist=USE_ARTIST)\n",
    "print(Data[np.random.randint(len(Data))], len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    1,   224,     6,    57,  2080,     5,   294,  1395,    13,\n",
      "             5,     3,   224,     6,    57,  2080,     5,   294,  1395,\n",
      "            13,     5,     3,   224,     6,    57,  2080,     5,   294,\n",
      "          1395,    13,     5,     3,   232,    71,   100,     8,   240,\n",
      "            21,     8,   326,    40,     3,  1056,     5,  1056,     5,\n",
      "          1056,     5,   294,  1395,    13],\n",
      "        [    1,    77,   502,  6420,    35,  8922,  3078,     9,   437,\n",
      "             4,  9041,     3,   112,    11,  9785,  3612,    81,    45,\n",
      "          5321,     8,  5731,     3,     9,  6706,   204,     8,   257,\n",
      "          1875,    53,   306,    58,    57,     8,    63,     3,   303,\n",
      "            58,    57,    15,  1190,   104,  2499,    53,  1930,    41,\n",
      "            58,   258,    74,     3,   141],\n",
      "        [    1,   282,     6,   109,    10,     4,    24,   179,     3,\n",
      "           122,   108,     8,    29,    25,  2551,     3,   122,    83,\n",
      "            10,     8,    67,    25,  2309,     3,   282,     7,    50,\n",
      "           165,    11,   493,    10,    26,    99,     3,    51,   176,\n",
      "             6,    23,     8,    63,   101,   438,     7,     5,  1287,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    1,     6,    49,    84,     7,    76,   127,     8,   105,\n",
      "             3,    24,  1195,   140,    16,  2537,    37,   639,     3,\n",
      "             6,    49,  1768,    61,  1007,    10,   881,     7,    96,\n",
      "             3,    12,  6241,    37,   131,    10,    13,     5,    51,\n",
      "            54,     3,    86,   313,    11,    91,    34,    13,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    1,     9,    75,    18,     7,    72,    13,     3,   408,\n",
      "            42,    24,   102,   171,    52,    12,    14,   190,     3,\n",
      "            75,    18,     7,   109,    13,     3,   162,    66,   145,\n",
      "            38,     5,    54,    20,    15,   163,    22,    11,   207,\n",
      "             3,     7,    75,    18,     7,   109,    13,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    1,  2167,  1720,   907,  3983,    11,  1599,     3,   312,\n",
      "           853,  1599,     4,  2136,     4,   150,     3,  2167,    11,\n",
      "          4528,   748,  1556,   743,     4,     3,   150,  9630,    11,\n",
      "           845,   764,     3,   555,  4348,  2090,   743,     4,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    1,     6,   684,   109,    10,   844,    22,     3,   252,\n",
      "            85,    60,  7241,    13,    61,     3,     7,  3645,   122,\n",
      "            18,     6,   121,   165,    59,     3,  1552,   104,    79,\n",
      "             3,   101,    57,   236,   104,    96,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    1,  1287,   176,     3,   256,   544,   607,    19,     3,\n",
      "             6,    29,    24,   256,   544,   607,    19,     3,   256,\n",
      "           544,   607,    19,     3,   256,   544,   607,    19,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), [50, 50, 45, 44, 43, 35, 33, 26], tensor([[  224,     6,    57,  2080,     5,   294,  1395,    13,     5,\n",
      "             3,   224,     6,    57,  2080,     5,   294,  1395,    13,\n",
      "             5,     3,   224,     6,    57,  2080,     5,   294,  1395,\n",
      "            13,     5,     3,   232,    71,   100,     8,   240,    21,\n",
      "             8,   326,    40,     3,  1056,     5,  1056,     5,  1056,\n",
      "             5,   294,  1395,    13,     5],\n",
      "        [   77,   502,  6420,    35,  8922,  3078,     9,   437,     4,\n",
      "          9041,     3,   112,    11,  9785,  3612,    81,    45,  5321,\n",
      "             8,  5731,     3,     9,  6706,   204,     8,   257,  1875,\n",
      "            53,   306,    58,    57,     8,    63,     3,   303,    58,\n",
      "            57,    15,  1190,   104,  2499,    53,  1930,    41,    58,\n",
      "           258,    74,     3,   141,     6],\n",
      "        [  282,     6,   109,    10,     4,    24,   179,     3,   122,\n",
      "           108,     8,    29,    25,  2551,     3,   122,    83,    10,\n",
      "             8,    67,    25,  2309,     3,   282,     7,    50,   165,\n",
      "            11,   493,    10,    26,    99,     3,    51,   176,     6,\n",
      "            23,     8,    63,   101,   438,     7,     5,  1287,     2,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    6,    49,    84,     7,    76,   127,     8,   105,     3,\n",
      "            24,  1195,   140,    16,  2537,    37,   639,     3,     6,\n",
      "            49,  1768,    61,  1007,    10,   881,     7,    96,     3,\n",
      "            12,  6241,    37,   131,    10,    13,     5,    51,    54,\n",
      "             3,    86,   313,    11,    91,    34,    13,     2,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    9,    75,    18,     7,    72,    13,     3,   408,    42,\n",
      "            24,   102,   171,    52,    12,    14,   190,     3,    75,\n",
      "            18,     7,   109,    13,     3,   162,    66,   145,    38,\n",
      "             5,    54,    20,    15,   163,    22,    11,   207,     3,\n",
      "             7,    75,    18,     7,   109,    13,     2,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 2167,  1720,   907,  3983,    11,  1599,     3,   312,   853,\n",
      "          1599,     4,  2136,     4,   150,     3,  2167,    11,  4528,\n",
      "           748,  1556,   743,     4,     3,   150,  9630,    11,   845,\n",
      "           764,     3,   555,  4348,  2090,   743,     4,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    6,   684,   109,    10,   844,    22,     3,   252,    85,\n",
      "            60,  7241,    13,    61,     3,     7,  3645,   122,    18,\n",
      "             6,   121,   165,    59,     3,  1552,   104,    79,     3,\n",
      "           101,    57,   236,   104,    96,     2,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [ 1287,   176,     3,   256,   544,   607,    19,     3,     6,\n",
      "            29,    24,   256,   544,   607,    19,     3,   256,   544,\n",
      "           607,    19,     3,   256,   544,   607,    19,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), [50, 50, 45, 44, 43, 35, 33, 26], None, [{'inp_ids': tensor([    1,   224,     6,    57,  2080,     5,   294,  1395,    13,\n",
      "            5,     3,   224,     6,    57,  2080,     5,   294,  1395,\n",
      "           13,     5,     3,   224,     6,    57,  2080,     5,   294,\n",
      "         1395,    13,     5,     3,   232,    71,   100,     8,   240,\n",
      "           21,     8,   326,    40,     3,  1056,     5,  1056,     5,\n",
      "         1056,     5,   294,  1395,    13]), 'inp_words': ['<START>', 'while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'must', 'have', 'been', 'the', 'hand', 'of', 'the', 'lord', '.', '<EOL>', 'glory', ',', 'glory', ',', 'glory', ',', 'somebody', 'touched', 'me'], 'out_ids': tensor([  224,     6,    57,  2080,     5,   294,  1395,    13,     5,\n",
      "            3,   224,     6,    57,  2080,     5,   294,  1395,    13,\n",
      "            5,     3,   224,     6,    57,  2080,     5,   294,  1395,\n",
      "           13,     5,     3,   232,    71,   100,     8,   240,    21,\n",
      "            8,   326,    40,     3,  1056,     5,  1056,     5,  1056,\n",
      "            5,   294,  1395,    13,     5]), 'artist_id': [], 'out_words': ['while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'while', 'i', 'was', 'praying', ',', 'somebody', 'touched', 'me', ',', '<EOL>', 'must', 'have', 'been', 'the', 'hand', 'of', 'the', 'lord', '.', '<EOL>', 'glory', ',', 'glory', ',', 'glory', ',', 'somebody', 'touched', 'me', ','], 'artist': []}, {'inp_ids': tensor([    1,    77,   502,  6420,    35,  8922,  3078,     9,   437,\n",
      "            4,  9041,     3,   112,    11,  9785,  3612,    81,    45,\n",
      "         5321,     8,  5731,     3,     9,  6706,   204,     8,   257,\n",
      "         1875,    53,   306,    58,    57,     8,    63,     3,   303,\n",
      "           58,    57,    15,  1190,   104,  2499,    53,  1930,    41,\n",
      "           58,   258,    74,     3,   141]), 'inp_words': ['<START>', 'from', 'men', 'armed', 'with', 'chewing', 'gum', 'and', 'fine', 'nylon', 'hose', '<EOL>', 'by', 'a', 'bicycle', 'factory', 'as', 'they', 'sounded', 'the', 'siren', '<EOL>', 'and', 'returned', 'into', 'the', 'dance', 'hall', 'she', 'knew', 'he', 'was', 'the', 'one', '<EOL>', 'though', 'he', 'was', \"n't\", 'tall', 'or', 'handsome', 'she', 'laughed', 'when', 'he', 'told', 'her', '<EOL>', '``'], 'out_ids': tensor([   77,   502,  6420,    35,  8922,  3078,     9,   437,     4,\n",
      "         9041,     3,   112,    11,  9785,  3612,    81,    45,  5321,\n",
      "            8,  5731,     3,     9,  6706,   204,     8,   257,  1875,\n",
      "           53,   306,    58,    57,     8,    63,     3,   303,    58,\n",
      "           57,    15,  1190,   104,  2499,    53,  1930,    41,    58,\n",
      "          258,    74,     3,   141,     6]), 'artist_id': [], 'out_words': ['from', 'men', 'armed', 'with', 'chewing', 'gum', 'and', 'fine', 'nylon', 'hose', '<EOL>', 'by', 'a', 'bicycle', 'factory', 'as', 'they', 'sounded', 'the', 'siren', '<EOL>', 'and', 'returned', 'into', 'the', 'dance', 'hall', 'she', 'knew', 'he', 'was', 'the', 'one', '<EOL>', 'though', 'he', 'was', \"n't\", 'tall', 'or', 'handsome', 'she', 'laughed', 'when', 'he', 'told', 'her', '<EOL>', '``', 'i'], 'artist': []}, {'inp_ids': tensor([    1,   282,     6,   109,    10,     4,    24,   179,     3,\n",
      "          122,   108,     8,    29,    25,  2551,     3,   122,    83,\n",
      "           10,     8,    67,    25,  2309,     3,   282,     7,    50,\n",
      "          165,    11,   493,    10,    26,    99,     3,    51,   176,\n",
      "            6,    23,     8,    63,   101,   438,     7,     5,  1287]), 'inp_words': ['<START>', 'maybe', 'i', 'need', 'to', 'refresh', 'your', 'mind', '<EOL>', 'think', 'about', 'the', 'love', 'we', 'shared', '<EOL>', 'think', 'back', 'to', 'the', 'time', 'we', 'cared', '<EOL>', 'maybe', 'you', 'can', 'find', 'a', 'reason', 'to', 'be', 'here', '<EOL>', 'oh', '...', 'i', \"'m\", 'the', 'one', 'who', 'loved', 'you', ',', 'mmm'], 'out_ids': tensor([  282,     6,   109,    10,     4,    24,   179,     3,   122,\n",
      "          108,     8,    29,    25,  2551,     3,   122,    83,    10,\n",
      "            8,    67,    25,  2309,     3,   282,     7,    50,   165,\n",
      "           11,   493,    10,    26,    99,     3,    51,   176,     6,\n",
      "           23,     8,    63,   101,   438,     7,     5,  1287,     2]), 'artist_id': [], 'out_words': ['maybe', 'i', 'need', 'to', 'refresh', 'your', 'mind', '<EOL>', 'think', 'about', 'the', 'love', 'we', 'shared', '<EOL>', 'think', 'back', 'to', 'the', 'time', 'we', 'cared', '<EOL>', 'maybe', 'you', 'can', 'find', 'a', 'reason', 'to', 'be', 'here', '<EOL>', 'oh', '...', 'i', \"'m\", 'the', 'one', 'who', 'loved', 'you', ',', 'mmm', '<END>'], 'artist': []}, {'inp_ids': tensor([    1,     6,    49,    84,     7,    76,   127,     8,   105,\n",
      "            3,    24,  1195,   140,    16,  2537,    37,   639,     3,\n",
      "            6,    49,  1768,    61,  1007,    10,   881,     7,    96,\n",
      "            3,    12,  6241,    37,   131,    10,    13,     5,    51,\n",
      "           54,     3,    86,   313,    11,    91,    34,    13]), 'inp_words': ['<START>', 'i', \"'ll\", 'make', 'you', 'come', 'through', 'the', 'night', '<EOL>', 'your', 'legs', 'around', 'my', 'waist', 'so', 'tight', '<EOL>', 'i', \"'ll\", 'slide', 'down', 'south', 'to', 'taste', 'you', 'right', '<EOL>', 'it', 'tastes', 'so', 'good', 'to', 'me', ',', 'oh', 'baby', '<EOL>', 'how', 'does', 'a', 'man', 'like', 'me'], 'out_ids': tensor([    6,    49,    84,     7,    76,   127,     8,   105,     3,\n",
      "           24,  1195,   140,    16,  2537,    37,   639,     3,     6,\n",
      "           49,  1768,    61,  1007,    10,   881,     7,    96,     3,\n",
      "           12,  6241,    37,   131,    10,    13,     5,    51,    54,\n",
      "            3,    86,   313,    11,    91,    34,    13,     2]), 'artist_id': [], 'out_words': ['i', \"'ll\", 'make', 'you', 'come', 'through', 'the', 'night', '<EOL>', 'your', 'legs', 'around', 'my', 'waist', 'so', 'tight', '<EOL>', 'i', \"'ll\", 'slide', 'down', 'south', 'to', 'taste', 'you', 'right', '<EOL>', 'it', 'tastes', 'so', 'good', 'to', 'me', ',', 'oh', 'baby', '<EOL>', 'how', 'does', 'a', 'man', 'like', 'me', '<END>'], 'artist': []}, {'inp_ids': tensor([   1,    9,   75,   18,    7,   72,   13,    3,  408,   42,\n",
      "          24,  102,  171,   52,   12,   14,  190,    3,   75,   18,\n",
      "           7,  109,   13,    3,  162,   66,  145,   38,    5,   54,\n",
      "          20,   15,  163,   22,   11,  207,    3,    7,   75,   18,\n",
      "           7,  109,   13]), 'inp_words': ['<START>', 'and', 'say', 'that', 'you', 'want', 'me', '<EOL>', 'open', 'up', 'your', 'heart', 'even', 'if', 'it', \"'s\", 'hard', '<EOL>', 'say', 'that', 'you', 'need', 'me', '<EOL>', 'better', 'let', 'him', 'know', ',', 'baby', 'do', \"n't\", 'put', 'on', 'a', 'show', '<EOL>', 'you', 'say', 'that', 'you', 'need', 'me'], 'out_ids': tensor([   9,   75,   18,    7,   72,   13,    3,  408,   42,   24,\n",
      "         102,  171,   52,   12,   14,  190,    3,   75,   18,    7,\n",
      "         109,   13,    3,  162,   66,  145,   38,    5,   54,   20,\n",
      "          15,  163,   22,   11,  207,    3,    7,   75,   18,    7,\n",
      "         109,   13,    2]), 'artist_id': [], 'out_words': ['and', 'say', 'that', 'you', 'want', 'me', '<EOL>', 'open', 'up', 'your', 'heart', 'even', 'if', 'it', \"'s\", 'hard', '<EOL>', 'say', 'that', 'you', 'need', 'me', '<EOL>', 'better', 'let', 'him', 'know', ',', 'baby', 'do', \"n't\", 'put', 'on', 'a', 'show', '<EOL>', 'you', 'say', 'that', 'you', 'need', 'me', '<END>'], 'artist': []}, {'inp_ids': tensor([    1,  2167,  1720,   907,  3983,    11,  1599,     3,   312,\n",
      "          853,  1599,     4,  2136,     4,   150,     3,  2167,    11,\n",
      "         4528,   748,  1556,   743,     4,     3,   150,  9630,    11,\n",
      "          845,   764,     3,   555,  4348,  2090,   743,     4]), 'inp_words': ['<START>', \"see'est\", 'encore', 'se', 'donner', 'a', 'lui', '<EOL>', 'et', 'quand', 'lui', 'viennent', 'ces', 'idees', 'la', '<EOL>', \"see'est\", 'a', 'peine', 'si', 'elle', 'en', 'rougit', '<EOL>', 'la', 'religieuse', 'a', 'comme', 'moi', '<EOL>', 'des', 'nuits', \"d'amour\", 'en', 'nostalgie'], 'out_ids': tensor([ 2167,  1720,   907,  3983,    11,  1599,     3,   312,   853,\n",
      "         1599,     4,  2136,     4,   150,     3,  2167,    11,  4528,\n",
      "          748,  1556,   743,     4,     3,   150,  9630,    11,   845,\n",
      "          764,     3,   555,  4348,  2090,   743,     4,     2]), 'artist_id': [], 'out_words': [\"see'est\", 'encore', 'se', 'donner', 'a', 'lui', '<EOL>', 'et', 'quand', 'lui', 'viennent', 'ces', 'idees', 'la', '<EOL>', \"see'est\", 'a', 'peine', 'si', 'elle', 'en', 'rougit', '<EOL>', 'la', 'religieuse', 'a', 'comme', 'moi', '<EOL>', 'des', 'nuits', \"d'amour\", 'en', 'nostalgie', '<END>'], 'artist': []}, {'inp_ids': tensor([    1,     6,   684,   109,    10,   844,    22,     3,   252,\n",
      "           85,    60,  7241,    13,    61,     3,     7,  3645,   122,\n",
      "           18,     6,   121,   165,    59,     3,  1552,   104,    79,\n",
      "            3,   101,    57,   236,   104,    96]), 'inp_words': ['<START>', 'i', 'dont', 'need', 'to', 'carry', 'on', '<EOL>', 'its', 'gon', 'na', 'weigh', 'me', 'down', '<EOL>', 'you', 'didnt', 'think', 'that', 'i', 'would', 'find', 'out', '<EOL>', 'whether', 'or', 'not', '<EOL>', 'who', 'was', 'wrong', 'or', 'right'], 'out_ids': tensor([    6,   684,   109,    10,   844,    22,     3,   252,    85,\n",
      "           60,  7241,    13,    61,     3,     7,  3645,   122,    18,\n",
      "            6,   121,   165,    59,     3,  1552,   104,    79,     3,\n",
      "          101,    57,   236,   104,    96,     2]), 'artist_id': [], 'out_words': ['i', 'dont', 'need', 'to', 'carry', 'on', '<EOL>', 'its', 'gon', 'na', 'weigh', 'me', 'down', '<EOL>', 'you', 'didnt', 'think', 'that', 'i', 'would', 'find', 'out', '<EOL>', 'whether', 'or', 'not', '<EOL>', 'who', 'was', 'wrong', 'or', 'right', '<END>'], 'artist': []}, {'inp_ids': tensor([    1,  1287,   176,     3,   256,   544,   607,    19,     3,\n",
      "            6,    29,    24,   256,   544,   607,    19,     3,   256,\n",
      "          544,   607,    19,     3,   256,   544,   607,    19]), 'inp_words': ['<START>', 'mmm', '...', '<EOL>', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'i', 'love', 'your', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'sweet', 'summer', 'lovin', \"'\"], 'out_ids': tensor([ 1287,   176,     3,   256,   544,   607,    19,     3,     6,\n",
      "           29,    24,   256,   544,   607,    19,     3,   256,   544,\n",
      "          607,    19,     3,   256,   544,   607,    19,     2]), 'artist_id': [], 'out_words': ['mmm', '...', '<EOL>', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'i', 'love', 'your', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'sweet', 'summer', 'lovin', \"'\", '<EOL>', 'sweet', 'summer', 'lovin', \"'\", '<END>'], 'artist': []}])\n",
      "chunking lyrics\n"
     ]
    }
   ],
   "source": [
    "def padding(data):\n",
    "    # gets samples (dicts) from Data\n",
    "    \n",
    "    def merge(seqs):\n",
    "        lengths = [len(s) for s in seqs]\n",
    "        max_len = np.max(lengths)\n",
    "        \n",
    "        padded_seqs = torch.ones(len(seqs), max_len).long()*PAD_ID\n",
    "        for i,s in enumerate(seqs):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = s[:end]\n",
    "                \n",
    "        return padded_seqs, lengths\n",
    "    \n",
    "    data.sort(key=lambda x:len(x['inp_ids']),reverse=True)\n",
    "    \n",
    "    inp_seqs,inp_lens = merge([x['inp_ids'] for x in data])\n",
    "    out_seqs,out_lens = merge([x['out_ids'] for x in data])\n",
    "    if Data.use_artist:\n",
    "        inp_artists = torch.from_numpy(np.array([x['artist_id'] for x in data]))\n",
    "    else:\n",
    "        inp_artists = None\n",
    "        \n",
    "    return inp_seqs,inp_lens,out_seqs,out_lens,inp_artists,data\n",
    "\n",
    "\n",
    "dataloader = DataLoader(Data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, collate_fn=padding)\n",
    "\n",
    "for i,batch in enumerate(dataloader):\n",
    "    print(batch)\n",
    "    break\n",
    "    \n",
    "ValData = LyricsDataset('lyrics/artists_val.pkl', vocab_file='lyrics/lyrics_top_artists.vocab', \n",
    "                        chunk_size=5,use_artist=USE_ARTIST)\n",
    "val_dataloader = DataLoader(ValData,  batch_size=BATCH_SIZE, num_workers=1, collate_fn=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "class LyricsRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, batch_size=BATCH_SIZE, \n",
    "                 n_layers=1, hidden_size=256, word_embedding_size=128, \n",
    "                 use_artist=True, embed_artist=False, num_artists=10, artist_embedding_size=32):\n",
    "        \n",
    "        super(LyricsRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batchsize = batch_size\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.word_embed_size = word_embedding_size\n",
    "        self.word_encoder = nn.Embedding(self.input_size, self.word_embed_size,padding_idx=PAD_ID)\n",
    "        self.lstm_input_size = self.word_embed_size\n",
    "        \n",
    "        self.use_artist = use_artist\n",
    "        if self.use_artist:\n",
    "            self.num_artists = num_artists\n",
    "            # either embed artist data or use a one-hot vector\n",
    "            if embed_artist:\n",
    "                self.artist_embed_size = artist_embedding_size\n",
    "                self.artist_encoder = nn.Embedding(self.num_artists, self.artist_embed_size)\n",
    "            else:\n",
    "                self.artist_embed_size = self.num_artists\n",
    "                self.artist_encoder = self.artist_onehot\n",
    "\n",
    "                    \n",
    "            self.lstm_input_size += self.artist_embed_size\n",
    "            \n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def artist_onehot(self, artist):\n",
    "        tensor = torch.zeros(self.batchsize,artist.size()[1],self.num_artists).to(device)\n",
    "        for i in range(tensor.size()[0]):\n",
    "            idx = artist[i,0]\n",
    "            tensor[i,:,idx] = 1\n",
    "        return tensor\n",
    "    \n",
    "    def init_hidden(self):\n",
    "         (Variable(torch.randn(self.n_layers, self.batchsize, self.hidden_size)).to(device),\n",
    "                Variable(torch.randn(self.n_layers, self.batchsize, self.hidden_size)).to(device))\n",
    "\n",
    "    def forward(self, input, input_lens):\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        if self.use_artist:\n",
    "            input,artist_input = input\n",
    "        \n",
    "        embed = self.word_encoder(input)\n",
    "        \n",
    "        if self.use_artist:\n",
    "            # repeat artist along sequence\n",
    "            artist_input = torch.unsqueeze(artist_input,dim=1)\n",
    "            artist_input = artist_input.expand(-1,input.size()[1]).to(device)\n",
    "            \n",
    "            artist_embed = self.artist_encoder(artist_input)\n",
    "            \n",
    "            # concatenate artist embedding to word embeddings\n",
    "            embed = torch.cat([embed,artist_embed],dim=2)\n",
    "                    \n",
    "        emb_pad = rnn.pack_padded_sequence(embed, input_lens, batch_first=True)\n",
    "        out_pad, self.hidden = self.lstm(emb_pad, self.hidden)\n",
    "        output, _ = rnn.pad_packed_sequence(out_pad, batch_first=True)\n",
    "        \n",
    "        # second RNN goes here\n",
    "\n",
    "        output = output.contiguous().view(-1,output.shape[2])\n",
    "        output = self.linear(output)\n",
    "        output = F.log_softmax(output,dim=1)\n",
    "        output = output.view(self.batchsize, -1, self.output_size)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def loss(self, Y_hat, Y):\n",
    "        Y = Y.view(-1)\n",
    "        Y_hat = Y_hat.view(-1,self.output_size)\n",
    "        mask = (Y != PAD_ID).float()\n",
    "        \n",
    "        non_pad_tokens = torch.sum(mask).item()\n",
    "        Y_hat = Y_hat[range(Y_hat.shape[0]), Y] * mask\n",
    "        \n",
    "        loss = -torch.sum(Y_hat) / non_pad_tokens\n",
    "        return loss\n",
    "    \n",
    "    def evaluate(self, prime_str=[START], artist=None, predict_len=100, temperature=0.8):\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # repeat input across batches\n",
    "        prime_input = Data.word_tensor(prime_str).expand(self.batchsize,-1).to(device)\n",
    "        predicted = prime_str\n",
    "        input_lens = [len(prime_str)-1]*self.batchsize\n",
    "        if self.use_artist:\n",
    "            artist = torch.from_numpy(np.array([artist]*self.batchsize))\n",
    "            \n",
    "        def get_input(inp):\n",
    "            if self.use_artist:\n",
    "                return [inp, artist]\n",
    "            else:\n",
    "                return inp\n",
    "\n",
    "        if len(prime_str) > 1:\n",
    "            # Use priming string to \"build up\" hidden state\n",
    "            self.forward(get_input(prime_input[:,:-1]), input_lens)\n",
    "            \n",
    "        inp = prime_input[:,-1].view(self.batchsize,1).to(device)\n",
    "        input_lens = [1]*self.batchsize\n",
    "        \n",
    "        for p in range(predict_len):\n",
    "            # just get first row, since all rows are the same\n",
    "            output = self.forward(get_input(inp), input_lens)[0]\n",
    "\n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_word = Data.vocab[top_i]\n",
    "            predicted += [predicted_word]\n",
    "            \n",
    "            if predicted_word == END:\n",
    "                break\n",
    "            print(top_i)\n",
    "            print(Data.word_tensor([predicted_word]))\n",
    "                \n",
    "            inp = Data.word_tensor([predicted_word]).expand(self.batchsize,1).to(device)\n",
    "\n",
    "        return ' '.join(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4371, device='cuda:0')\n",
      "tensor([ 4371])\n",
      "tensor(578, device='cuda:0')\n",
      "tensor([ 578])\n",
      "tensor(4760, device='cuda:0')\n",
      "tensor([ 4760])\n",
      "tensor(1512, device='cuda:0')\n",
      "tensor([ 1512])\n",
      "tensor(6857, device='cuda:0')\n",
      "tensor([ 6857])\n",
      "tensor(9787, device='cuda:0')\n",
      "tensor([ 9787])\n",
      "tensor(253, device='cuda:0')\n",
      "tensor([ 253])\n",
      "tensor(8232, device='cuda:0')\n",
      "tensor([ 8232])\n",
      "tensor(7964, device='cuda:0')\n",
      "tensor([ 7964])\n",
      "tensor(2179, device='cuda:0')\n",
      "tensor([ 2179])\n",
      "tensor(6215, device='cuda:0')\n",
      "tensor([ 6215])\n",
      "tensor(8205, device='cuda:0')\n",
      "tensor([ 8205])\n",
      "tensor(7002, device='cuda:0')\n",
      "tensor([ 7002])\n",
      "tensor(2310, device='cuda:0')\n",
      "tensor([ 2310])\n",
      "tensor(4051, device='cuda:0')\n",
      "tensor([ 4051])\n",
      "tensor(2130, device='cuda:0')\n",
      "tensor([ 2130])\n",
      "tensor(4214, device='cuda:0')\n",
      "tensor([ 4214])\n",
      "tensor(9670, device='cuda:0')\n",
      "tensor([ 9670])\n",
      "tensor(3539, device='cuda:0')\n",
      "tensor([ 3539])\n",
      "tensor(5501, device='cuda:0')\n",
      "tensor([ 5501])\n",
      "tensor(7423, device='cuda:0')\n",
      "tensor([ 7423])\n",
      "tensor(8595, device='cuda:0')\n",
      "tensor([ 8595])\n",
      "tensor(886, device='cuda:0')\n",
      "tensor([ 886])\n",
      "tensor(7732, device='cuda:0')\n",
      "tensor([ 7732])\n",
      "tensor(4266, device='cuda:0')\n",
      "tensor([ 4266])\n",
      "tensor(7350, device='cuda:0')\n",
      "tensor([ 7350])\n",
      "tensor(7834, device='cuda:0')\n",
      "tensor([ 7834])\n",
      "tensor(1723, device='cuda:0')\n",
      "tensor([ 1723])\n",
      "tensor(3126, device='cuda:0')\n",
      "tensor([ 3126])\n",
      "tensor(4755, device='cuda:0')\n",
      "tensor([ 4755])\n",
      "tensor(2110, device='cuda:0')\n",
      "tensor([ 2110])\n",
      "tensor(7886, device='cuda:0')\n",
      "tensor([ 7886])\n",
      "tensor(3764, device='cuda:0')\n",
      "tensor([ 3764])\n",
      "tensor(4702, device='cuda:0')\n",
      "tensor([ 4702])\n",
      "tensor(6612, device='cuda:0')\n",
      "tensor([ 6612])\n",
      "tensor(7666, device='cuda:0')\n",
      "tensor([ 7666])\n",
      "tensor(1540, device='cuda:0')\n",
      "tensor([ 1540])\n",
      "tensor(8974, device='cuda:0')\n",
      "tensor([ 8974])\n",
      "tensor(5150, device='cuda:0')\n",
      "tensor([ 5150])\n",
      "tensor(7458, device='cuda:0')\n",
      "tensor([ 7458])\n",
      "tensor(6849, device='cuda:0')\n",
      "tensor([ 6849])\n",
      "tensor(3875, device='cuda:0')\n",
      "tensor([ 3875])\n",
      "tensor(4765, device='cuda:0')\n",
      "tensor([ 4765])\n",
      "tensor(145, device='cuda:0')\n",
      "tensor([ 145])\n",
      "tensor(7259, device='cuda:0')\n",
      "tensor([ 7259])\n",
      "tensor(9582, device='cuda:0')\n",
      "tensor([ 9582])\n",
      "tensor(7776, device='cuda:0')\n",
      "tensor([ 7776])\n",
      "tensor(4384, device='cuda:0')\n",
      "tensor([ 4384])\n",
      "tensor(516, device='cuda:0')\n",
      "tensor([ 516])\n",
      "tensor(4856, device='cuda:0')\n",
      "tensor([ 4856])\n",
      "tensor(8330, device='cuda:0')\n",
      "tensor([ 8330])\n",
      "tensor(3083, device='cuda:0')\n",
      "tensor([ 3083])\n",
      "tensor(6152, device='cuda:0')\n",
      "tensor([ 6152])\n",
      "tensor(676, device='cuda:0')\n",
      "tensor([ 676])\n",
      "tensor(4615, device='cuda:0')\n",
      "tensor([ 4615])\n",
      "tensor(1028, device='cuda:0')\n",
      "tensor([ 1028])\n",
      "tensor(9864, device='cuda:0')\n",
      "tensor([ 9864])\n",
      "tensor(3771, device='cuda:0')\n",
      "tensor([ 3771])\n",
      "tensor(5375, device='cuda:0')\n",
      "tensor([ 5375])\n",
      "tensor(6653, device='cuda:0')\n",
      "tensor([ 6653])\n",
      "tensor(9043, device='cuda:0')\n",
      "tensor([ 9043])\n",
      "tensor(9649, device='cuda:0')\n",
      "tensor([ 9649])\n",
      "tensor(6644, device='cuda:0')\n",
      "tensor([ 6644])\n",
      "tensor(8048, device='cuda:0')\n",
      "tensor([ 8048])\n",
      "tensor(1811, device='cuda:0')\n",
      "tensor([ 1811])\n",
      "tensor(2818, device='cuda:0')\n",
      "tensor([ 2818])\n",
      "tensor(350, device='cuda:0')\n",
      "tensor([ 350])\n",
      "tensor(7403, device='cuda:0')\n",
      "tensor([ 7403])\n",
      "tensor(5367, device='cuda:0')\n",
      "tensor([ 5367])\n",
      "tensor(4652, device='cuda:0')\n",
      "tensor([ 4652])\n",
      "tensor(4074, device='cuda:0')\n",
      "tensor([ 4074])\n",
      "tensor(1506, device='cuda:0')\n",
      "tensor([ 1506])\n",
      "tensor(585, device='cuda:0')\n",
      "tensor([ 585])\n",
      "tensor(1565, device='cuda:0')\n",
      "tensor([ 1565])\n",
      "tensor(6780, device='cuda:0')\n",
      "tensor([ 6780])\n",
      "tensor(2913, device='cuda:0')\n",
      "tensor([ 2913])\n",
      "tensor(6429, device='cuda:0')\n",
      "tensor([ 6429])\n",
      "tensor(5023, device='cuda:0')\n",
      "tensor([ 5023])\n",
      "tensor(7322, device='cuda:0')\n",
      "tensor([ 7322])\n",
      "tensor(9712, device='cuda:0')\n",
      "tensor([ 9712])\n",
      "tensor(4779, device='cuda:0')\n",
      "tensor([ 4779])\n",
      "tensor(2263, device='cuda:0')\n",
      "tensor([ 2263])\n",
      "tensor(5541, device='cuda:0')\n",
      "tensor([ 5541])\n",
      "tensor(6955, device='cuda:0')\n",
      "tensor([ 6955])\n",
      "tensor(5748, device='cuda:0')\n",
      "tensor([ 5748])\n",
      "tensor(1901, device='cuda:0')\n",
      "tensor([ 1901])\n",
      "tensor(3302, device='cuda:0')\n",
      "tensor([ 3302])\n",
      "tensor(4160, device='cuda:0')\n",
      "tensor([ 4160])\n",
      "tensor(5535, device='cuda:0')\n",
      "tensor([ 5535])\n",
      "tensor(4509, device='cuda:0')\n",
      "tensor([ 4509])\n",
      "tensor(9392, device='cuda:0')\n",
      "tensor([ 9392])\n",
      "tensor(9070, device='cuda:0')\n",
      "tensor([ 9070])\n",
      "tensor(628, device='cuda:0')\n",
      "tensor([ 628])\n",
      "tensor(3444, device='cuda:0')\n",
      "tensor([ 3444])\n",
      "tensor(8156, device='cuda:0')\n",
      "tensor([ 8156])\n",
      "tensor(2985, device='cuda:0')\n",
      "tensor([ 2985])\n",
      "tensor(3068, device='cuda:0')\n",
      "tensor([ 3068])\n",
      "tensor(4402, device='cuda:0')\n",
      "tensor([ 4402])\n",
      "tensor(9325, device='cuda:0')\n",
      "tensor([ 9325])\n",
      "tensor(6830, device='cuda:0')\n",
      "tensor([ 6830])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "print_every = 1000\n",
    "plot_every = 1000\n",
    "lr = 0.005\n",
    "\n",
    "model = LyricsRNN(Data.vocab_len, Data.vocab_len, use_artist=USE_ARTIST).to(device) # , num_artists=Data.num_artists,hidden_size=6, word_embedding_size=10, \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        inp_seqs,inp_lens,out_seqs,out_lens,inp_artists,data = batch\n",
    "        \n",
    "        if Data.use_artist:\n",
    "            inp, target = [inp_seqs.to(device),inp_artists], out_seqs.to(device)\n",
    "        else:\n",
    "            inp, target = inp_seqs.to(device), out_seqs.to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        predictions = model(inp, inp_lens)\n",
    "        model.evaluate()\n",
    "        break\n",
    "        loss = model.loss(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_avg += loss\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "            print(model.evaluate(), '\\n')\n",
    "\n",
    "        if i % plot_every == 0:\n",
    "            all_losses.append(loss_avg / plot_every)\n",
    "            loss_avg = 0\n",
    "    break\n",
    "    val_loss = 0\n",
    "    for i,batch in enumerate(val_dataloader):\n",
    "        inp_seqs,inp_lens,out_seqs,out_lens,inp_artists,data = batch\n",
    "        \n",
    "        if Data.use_artist:\n",
    "            inp, target = [inp_seqs.to(device),inp_artists], out_seqs.to(device)\n",
    "        else:\n",
    "            inp, target = inp_seqs.to(device), out_seqs.to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        predictions = model(inp, inp_lens)\n",
    "        loss = model.loss(predictions, target)\n",
    "        val_loss += loss\n",
    "    avg_val_loss = val_loss / i\n",
    "    print('Validation loss: %.4f'%avg_val_loss)\n",
    "    if avg_val_loss > all_losses[-1]:\n",
    "        break\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses': all_losses\n",
    "#         'hyperparameters': {\n",
    "#             'input_file': pkl_file,\n",
    "#             'vocab_file': vocab_file,\n",
    "#             'vocab_size': vocab_size,\n",
    "#             'chunk_size':,\n",
    "#             'max_seq_len':,\n",
    "#             'use_artist':,\n",
    "#             'input_size':,\n",
    "#             'output_size':,\n",
    "#             'batch_size':,\n",
    "#             'n_layers':,\n",
    "#             'hidden_size':,\n",
    "#             'word_embedding_size':,\n",
    "#             'num_artists':,\n",
    "#             'artist_embedding_size':\n",
    "#         }\n",
    "    }, 'checkpoints/lyrics_model-e%05d.pt'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cee4e9858e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'figure'"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "\n",
    "print(model.evaluate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
